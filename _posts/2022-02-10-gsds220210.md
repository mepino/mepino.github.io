---
title: "부트캠프"
excerpt: "컴퓨팅 9, 수학 7~8, 통계 #1"

categories:
  - GSDS
last_modified_at: 2022-02-10
---

> Big O, MergeSort and Recursion

> Arrays, Linked lists, Stacks, and Queues

# Matrix Decompose

> Determinant

- Laplace Expansion

> Trace : nxn matrix에 대해 diagonal element 더한거

- tr(AB) = tr(BA)

> Eigen values & Eigen vectors & Eigen space

- Ax = λx (λ:Eigen value, x:Eigen vector[not zero vector]) -> A라는 linear mapping에는 특별한 λ와 x를 찾을 수 있다.
- (A - λIn)x = 0 ↔ x ∈ ker(A-λIn) ↔ rank(A-λIn) < n ↔ "det(A-λIn) = 0"
  마지막 "det(A-λIn) = 0"로 eigen value, eigen vector 찾을때 쓴다.
- 각각의 eigen vector는 independent하다.
- det(A)= λ1 _ λ2 _ ... \* λn, tr(A)=Σλi

> Diagonalizable : A is Diagonalizable

- D = P^-1 A P -> PD = AP -> c_i* p_i = A* p_i -> Eigen vector랑 eigen value로 diagonalize한다는 뜻
- A = PDP^-1 (Eigen-decomposition) <- P의 역행렬 존재해야 함:P가 full rank=eigen vector들이 n 만들 수 있어야한다
- Theorem> A symmetric matrix S는 항상 diagonalizable하다. (SVD에서 A^T\*A는 symetric하다는거에 써먹을 예정)

> Singular Value Decomposition (SVD)

- A가 square matirix 아닐때도 쓸수있는 decomposition 방법 : SVD
- 왜 SVD 많이 쓰나? A라는 mxn 매트릭스 형태의 데이터가 있을 때, 대표적인 얼굴형태 m개 뽑아서(U), 중요한 n개만 추리고(Σ), 가중치(V^T) 주는거.
- Theorem> A = UΣV^T (Σ가 D 역할, U와 V는 orthogonal matrix)
  (orthogonal matrix U에 대해서 U^T=U^-1)

> 통계 시작

- Quanitify uncertainty
- Probability ~ 확률의 정의 : a measure for an event set (Sample Space의 Subset을 Real number로 변화시키는 Function), 확률의 의미> Frequency / Degree of belief
- Inference(Learning)

1. Data Generating Process

Sample Space (ex. {HH, HT, TH, TT})
Subset A (ex. First toss in Head ~ {HH, HT})

- terminology
  <img src="{{ site.url }}/assets/images/20220211_gsds_1.png" width="100%" height="100%"/>

- Independent : P(AB) = P(A)P(B)
- Conditional Probability : P(A|B) = P(AB)/P(B)

- Bayes' Theorem : P(A|B)를 P(B|A)로 바꾸는거
  P(A|B) = P(AB)/P(B) = P(B|A) \* P(A)/P(B)
  Prior to Posterior
  ex. spam detector, A1:spam, A2:low priority, A3:high priority
  P(A1)=0.7, P(A2)=0.2, P(A3)=0.1
  B:"free"라는 단어를 포함하는 email
  P(B|A1)=0.9, P(B|A2)=0.01, P(B|A3)=0.01

늘 P(B) 구하는게 어렵다..
