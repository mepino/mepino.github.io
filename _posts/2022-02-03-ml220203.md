---
title: "CAPTUM"
excerpt: " A unified and generic model interpretability library for PyTorch"

categories:
  - ML
last_modified_at: 2022-02-03
---

XAI

> 설명가능 - explainability

- transparency, explainability, interpretability 포함

> 구분

- 방법론에 있어서는 Gradient, Perturbation, Other..
- 분석 Scope 기준으로는 Primary, Neuron, Layer

> Gradient

- 결과에 영향미치는걸 backward pass에 주목하여 확인 (ex. CAM)

> Perturbation

- 입력값 변화시키면서 영향도 분석

<img src="{{ site.url }}/assets/images/captum.png" width="100%" height="100%"/>

Autoencoder asset pricing model 논문에서 나온 방식은 Feature Ablation 방식이다.
https://captum.ai/tutorials/Resnet_TorchVision_Ablation
